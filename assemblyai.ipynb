{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOtuT3MLeUcg/LnnT5BjrfX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sallumandya1995/datascience/blob/master/assemblyai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VECS5DxdeQNU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pd-tngQkiEF7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L52bmJXkAMQz"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YL179UtGKweb"
      },
      "source": [
        "Load the pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAZa9giriEGE"
      },
      "source": [
        " **Cohere one shot lerning capbility**\n",
        " \n",
        " \n",
        "Using power of Cohere's command model to write a detailed caption of an image describing the interior design of living room and letting stable diffusion do the remaining magic\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IzxquLwriEGF"
      },
      "outputs": [],
      "source": [
        "#@title init libraries for GPu\n",
        "!pip install -qq cohere\n",
        "!pip install -qq gradio\n",
        "!pip install -qq accelerate\n",
        "!pip install -qq diffusers==0.8.0   ftfy\n",
        "!pip install -qq \"ipywidgets>=7,<8\"\n",
        " \n",
        "!pip install git+https://github.com/huggingface/transformers\n",
        "import inspect\n",
        "import warnings\n",
        "from typing import List, Optional, Union\n",
        "\n",
        "import torch\n",
        "from torch import autocast\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "from diffusers import StableDiffusionImg2ImgPipeline\n",
        "  \n",
        "import random\n",
        "import inspect\n",
        "import warnings\n",
        "from typing import List, Optional, Union\n",
        "\n",
        "import torch\n",
        "from torch import autocast\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "from diffusers import StableDiffusionImg2ImgPipeline\n",
        "\n",
        "import requests\n",
        "import os\n",
        " \n",
        "from IPython.display import Image, display\n",
        "import cohere\n",
        "\n",
        "from huggingface_hub import notebook_login\n",
        "import inspect\n",
        "import warnings\n",
        "from typing import List, Optional, Union\n",
        "\n",
        "import torch\n",
        "from torch import autocast\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "from diffusers import StableDiffusionImg2ImgPipeline\n",
        "import inspect\n",
        "import warnings\n",
        "from typing import List, Optional, Union\n",
        " \n",
        "\n",
        " \n",
        "\n",
        "!python -c \"from huggingface_hub.hf_api import HfFolder; HfFolder.save_token('xxxxxxxxxxxxxxxx')\" #pass huggingface token as arguement\n",
        "\n",
        " \n",
        "co = cohere.Client('xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx')   #use your cohere api inside\n",
        "\n",
        "os.system(\"gdown https://drive.google.com/uc?id=1mT9ewx86PSrc43b-ax47l1E2UzR7Ln4j -O RealESRGAN_x8.pth\")\n",
        "device = \"cuda\"\n",
        "model_path = \"prompthero/midjourney-v4-diffusion\"\n",
        "model_path=\"stabilityai/stable-diffusion-2\"\n",
        "\n",
        "model_path = \"CompVis/stable-diffusion-v1-4\"\n",
        "\n",
        "pipe = StableDiffusionImg2ImgPipeline.from_pretrained(\n",
        "    model_path,\n",
        "#     revision=\"fp16\",  # comment for prompt hero version\n",
        "    torch_dtype=torch.float16\n",
        "    ,use_auth_token=True\n",
        ")\n",
        "pipe = pipe.to(device)\n",
        "\n",
        "\n",
        "#upscalers\n",
        "\n",
        "!git clone https://huggingface.co/spaces/Xhaheen/Face-Real-ESRGAN\n",
        "!pip install -q gdown gradio\n",
        "!cp -r Face-Real-ESRGAN/. .\n",
        "\n",
        "# %cd Face-Real-ESRGAN"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title using cohere  and gpus\n",
        "import csv\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "import re\n",
        "import datetime\n",
        "\n",
        "\n",
        " \n",
        "import random\n",
        "import torch\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from realesrgan import RealESRGAN\n",
        "import os\n",
        "import gradio as gr\n",
        "import os\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "!wget https://huggingface.co/spaces/Xhaheen/Baith-al-suroor/resolve/main/1.png\n",
        "!wget https://huggingface.co/spaces/Xhaheen/Face-Real-ESRGAN/resolve/main/RealESRGAN_x8.pth \n",
        "if not os.path.exists(\"RealESRGAN_x8.pth\"):\n",
        "  !wget https://huggingface.co/spaces/Xhaheen/Face-Real-ESRGAN/resolve/main/RealESRGAN_x8.pth\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "\n",
        "        \n",
        "current_time = datetime.datetime.now()\n",
        "def generate_caption_keywords(prompt, model='command-xlarge-20221108', max_tokens=200, temperature=random.uniform(0.1, 2), k=0, p=0.75, frequency_penalty=0, presence_penalty=0, stop_sequences=[]):\n",
        "    \n",
        "    response = co.generate(\n",
        "      model=model,\n",
        "      prompt=prompt,\n",
        "      max_tokens=max_tokens,\n",
        "      temperature=temperature,\n",
        "      k=k,\n",
        "      p=p,\n",
        "      frequency_penalty=frequency_penalty,\n",
        "      presence_penalty=presence_penalty,\n",
        "      stop_sequences=stop_sequences,\n",
        "      return_likelihoods='NONE')\n",
        "\n",
        "    def highlight_keywords(text):\n",
        "        keywords = []\n",
        "        text = text.lower()\n",
        "        text = re.sub(r'[^a-z\\s]', '', text) # remove punctuation\n",
        "        text = re.sub(r'\\b(the|and|of)\\b', '', text) # remove stop words\n",
        "        words = text.split()\n",
        "        for word in words:\n",
        "            if word not in keywords:\n",
        "                keywords.append(word)\n",
        "        return keywords\n",
        "\n",
        "    caption = response.generations[0].text\n",
        "    keywords = highlight_keywords(caption)\n",
        "    keywords_string = ', '.join(keywords)\n",
        "\n",
        "    return caption, keywords_string\n",
        "\n",
        "\n",
        "def img2img( path ,is_HD,design,x_prompt,alt_prompt,strength,guidance_scale,steps):\n",
        "  current_time = datetime.datetime.now()\n",
        "  prompt = f'write a detailed caption of an image describing the  {design}'\n",
        "  \n",
        "  try:\n",
        "        caption, keywords = generate_caption_keywords(prompt)\n",
        "        prompt = keywords\n",
        "  except:\n",
        "    \n",
        "    prompt = design\n",
        "    \n",
        "\n",
        "  if x_prompt == True:\n",
        "    \n",
        "    prompt=alt_prompt\n",
        "    print(alt_prompt ,strength,7.9,current_time)\n",
        "     \n",
        " \n",
        "  generator = torch.Generator(device=device).manual_seed(1024) \n",
        "  \n",
        " \n",
        "    \n",
        "  init_img =Image.open(path)\n",
        "#   init_img.save(f\"original_{prompts[0]}_strength{strength}_guidance_{guidance_scale}.jpeg\")\n",
        "\n",
        "  with autocast(\"cuda\"):\n",
        "        \n",
        "      \n",
        "      image2 = pipe(prompt=prompt , init_image=init_img, strength=strength,num_inference_steps=steps, guidance_scale=guidance_scale, generator=generator).images[0]\n",
        "      \n",
        " #remove if condition in above line if it does not fits\n",
        "      if is_HD == True:\n",
        "\n",
        "\n",
        "        model8 = RealESRGAN(device, scale=8)\n",
        "\n",
        "         \n",
        "        model8.load_weights('RealESRGAN_x8.pth')\n",
        "        image2 = model8.predict(image2.convert('RGB'))\n",
        "        \n",
        " \n",
        "      image2.save(\"image2.jpeg\")\n",
        "      image2.save(f\"new_{current_time}{design}_strength{strength}_guidance_{guidance_scale}.jpeg\")\n",
        "#       print(design,prompt ,strength,7.9,current_time)\n",
        "      # Import the pyplot module from Matplotlib\n",
        "\n",
        " \n",
        "\n",
        "      # Display the image using the imshow function\n",
        "      plt.imshow(image2)\n",
        "\n",
        "      # Show the plot on the screen\n",
        "      plt.show()\n",
        "\n",
        "      print(f\"new_{current_time}{design}_strength{strength}_guidance_{guidance_scale}.jpeg\")\n",
        "      current_image=f\"new_{current_time}{design}_strength{strength}_guidance_{guidance_scale}.jpeg\"\n",
        "      \n",
        "\n",
        "\n",
        "      # Download the file # comment for kaggle\n",
        "      from google.colab import files\n",
        "      files.download(f\"new_{current_time}{design}_strength{strength}_guidance_{guidance_scale}.jpeg\")\n",
        " \n",
        "      \n",
        "  def append_csv(filename, row):\n",
        "      with open(filename, \"a\") as f:\n",
        "          writer = csv.writer(f)\n",
        "          writer.writerow(row)\n",
        "# records the data bases to store inputs and outputs for future reference\n",
        "  append_csv(\"database.csv\", [current_time,strength,guidance_scale,f\"new_{prompt}_strength{strength}_guidance_{guidance_scale}.jpeg\"])\n",
        "\n",
        "  \n",
        "  return image2\n",
        "\n",
        " "
      ],
      "metadata": {
        "id": "1fNj42p-X57v"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}